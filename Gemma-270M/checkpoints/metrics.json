{
  "training_history": [
    {
      "step": 10,
      "loss": 83.75286102294922,
      "learning_rate": 9.995066821070681e-05,
      "tokens_per_second": 27498.790210484192,
      "time": 0.29790401458740234
    },
    {
      "step": 20,
      "loss": 80.55435371398926,
      "learning_rate": 9.980286753286197e-05,
      "tokens_per_second": 26703.768064039792,
      "time": 0.30677318572998047
    },
    {
      "step": 30,
      "loss": 78.01177597045898,
      "learning_rate": 9.955718126821727e-05,
      "tokens_per_second": 27400.78771325288,
      "time": 0.2989695072174072
    },
    {
      "step": 40,
      "loss": 75.45466613769531,
      "learning_rate": 9.921457902821581e-05,
      "tokens_per_second": 27418.958141880623,
      "time": 0.29877138137817383
    },
    {
      "step": 50,
      "loss": 72.68162250518799,
      "learning_rate": 9.877641290737888e-05,
      "tokens_per_second": 27532.944723746947,
      "time": 0.2975344657897949
    },
    {
      "step": 60,
      "loss": 70.1606912612915,
      "learning_rate": 9.824441214720633e-05,
      "tokens_per_second": 27491.26559037062,
      "time": 0.2979855537414551
    },
    {
      "step": 70,
      "loss": 67.74726390838623,
      "learning_rate": 9.762067631165051e-05,
      "tokens_per_second": 27052.931059379116,
      "time": 0.3028137683868408
    },
    {
      "step": 80,
      "loss": 65.44807147979736,
      "learning_rate": 9.69076670010966e-05,
      "tokens_per_second": 27374.1332929676,
      "time": 0.29926061630249023
    },
    {
      "step": 90,
      "loss": 63.21564817428589,
      "learning_rate": 9.610819813755039e-05,
      "tokens_per_second": 25817.94779414914,
      "time": 0.31729865074157715
    },
    {
      "step": 100,
      "loss": 61.18361759185791,
      "learning_rate": 9.52254248593737e-05,
      "tokens_per_second": 27191.55501741824,
      "time": 0.3012700080871582
    },
    {
      "step": 110,
      "loss": 59.33790159225464,
      "learning_rate": 9.426283106939473e-05,
      "tokens_per_second": 26671.203782433975,
      "time": 0.307147741317749
    },
    {
      "step": 120,
      "loss": 57.62104892730713,
      "learning_rate": 9.322421568553528e-05,
      "tokens_per_second": 26271.825521942417,
      "time": 0.311816930770874
    },
    {
      "step": 130,
      "loss": 55.41879844665527,
      "learning_rate": 9.211367764821722e-05,
      "tokens_per_second": 26789.903005154523,
      "time": 0.3057868480682373
    },
    {
      "step": 140,
      "loss": 54.18129110336304,
      "learning_rate": 9.093559974371722e-05,
      "tokens_per_second": 26771.617792509034,
      "time": 0.3059957027435303
    },
    {
      "step": 150,
      "loss": 52.17731857299805,
      "learning_rate": 8.969463130731182e-05,
      "tokens_per_second": 27804.562514211913,
      "time": 0.2946279048919678
    },
    {
      "step": 160,
      "loss": 50.29765558242798,
      "learning_rate": 8.83956698744749e-05,
      "tokens_per_second": 26070.375654514814,
      "time": 0.3142263889312744
    },
    {
      "step": 170,
      "loss": 48.86989450454712,
      "learning_rate": 8.704384185254286e-05,
      "tokens_per_second": 26834.78236638348,
      "time": 0.30527544021606445
    },
    {
      "step": 180,
      "loss": 48.26336669921875,
      "learning_rate": 8.56444822891268e-05,
      "tokens_per_second": 27163.523417254186,
      "time": 0.30158090591430664
    },
    {
      "step": 190,
      "loss": 45.763619899749756,
      "learning_rate": 8.420311381711693e-05,
      "tokens_per_second": 26747.65109151643,
      "time": 0.30626988410949707
    },
    {
      "step": 200,
      "loss": 45.26717662811279,
      "learning_rate": 8.272542485937368e-05,
      "tokens_per_second": 26733.520454877893,
      "time": 0.30643177032470703
    },
    {
      "step": 210,
      "loss": 44.07549810409546,
      "learning_rate": 8.121724717912137e-05,
      "tokens_per_second": 26412.810439750505,
      "time": 0.310152530670166
    },
    {
      "step": 220,
      "loss": 44.13863182067871,
      "learning_rate": 7.968453286464312e-05,
      "tokens_per_second": 27192.480357715212,
      "time": 0.30125975608825684
    },
    {
      "step": 230,
      "loss": 43.00026226043701,
      "learning_rate": 7.813333083910761e-05,
      "tokens_per_second": 26161.765893051164,
      "time": 0.3131287097930908
    },
    {
      "step": 240,
      "loss": 42.169716358184814,
      "learning_rate": 7.656976298823283e-05,
      "tokens_per_second": 26515.94933223441,
      "time": 0.3089461326599121
    },
    {
      "step": 250,
      "loss": 42.14245414733887,
      "learning_rate": 7.499999999999998e-05,
      "tokens_per_second": 27466.915838362846,
      "time": 0.2982497215270996
    },
    {
      "step": 260,
      "loss": 41.03465795516968,
      "learning_rate": 7.343023701176717e-05,
      "tokens_per_second": 26468.601319434387,
      "time": 0.30949878692626953
    },
    {
      "step": 270,
      "loss": 40.53408670425415,
      "learning_rate": 7.18666691608924e-05,
      "tokens_per_second": 25178.074952973944,
      "time": 0.3253624439239502
    },
    {
      "step": 280,
      "loss": 39.6713171005249,
      "learning_rate": 7.03154671353569e-05,
      "tokens_per_second": 26017.78579687648,
      "time": 0.314861536026001
    },
    {
      "step": 290,
      "loss": 39.38696527481079,
      "learning_rate": 6.878275282087864e-05,
      "tokens_per_second": 27905.95586179787,
      "time": 0.29355740547180176
    },
    {
      "step": 300,
      "loss": 38.799983501434326,
      "learning_rate": 6.727457514062633e-05,
      "tokens_per_second": 27013.201165759012,
      "time": 0.30325913429260254
    },
    {
      "step": 310,
      "loss": 39.36242055892944,
      "learning_rate": 6.579688618288308e-05,
      "tokens_per_second": 27810.481270679953,
      "time": 0.29456520080566406
    },
    {
      "step": 320,
      "loss": 38.7549147605896,
      "learning_rate": 6.43555177108732e-05,
      "tokens_per_second": 25722.94942362487,
      "time": 0.31847047805786133
    },
    {
      "step": 330,
      "loss": 38.171889305114746,
      "learning_rate": 6.295615814745714e-05,
      "tokens_per_second": 27785.49560854823,
      "time": 0.2948300838470459
    },
    {
      "step": 340,
      "loss": 38.060317039489746,
      "learning_rate": 6.160433012552509e-05,
      "tokens_per_second": 26744.98614714369,
      "time": 0.30630040168762207
    },
    {
      "step": 350,
      "loss": 37.88969612121582,
      "learning_rate": 6.030536869268818e-05,
      "tokens_per_second": 27290.946555087467,
      "time": 0.3001728057861328
    },
    {
      "step": 360,
      "loss": 37.791237354278564,
      "learning_rate": 5.9064400256282764e-05,
      "tokens_per_second": 27930.40947950359,
      "time": 0.2933003902435303
    },
    {
      "step": 370,
      "loss": 37.331239223480225,
      "learning_rate": 5.788632235178279e-05,
      "tokens_per_second": 27225.554156762068,
      "time": 0.30089378356933594
    },
    {
      "step": 380,
      "loss": 37.00485038757324,
      "learning_rate": 5.677578431446471e-05,
      "tokens_per_second": 24908.161956479977,
      "time": 0.3288881778717041
    },
    {
      "step": 390,
      "loss": 36.9003210067749,
      "learning_rate": 5.5737168930605275e-05,
      "tokens_per_second": 27209.815222091118,
      "time": 0.3010678291320801
    },
    {
      "step": 400,
      "loss": 36.48701095581055,
      "learning_rate": 5.477457514062632e-05,
      "tokens_per_second": 25173.22355106335,
      "time": 0.3254251480102539
    },
    {
      "step": 410,
      "loss": 36.547890186309814,
      "learning_rate": 5.3891801862449625e-05,
      "tokens_per_second": 27168.87161187121,
      "time": 0.30152153968811035
    },
    {
      "step": 420,
      "loss": 35.815940380096436,
      "learning_rate": 5.3092332998903414e-05,
      "tokens_per_second": 27609.31585908535,
      "time": 0.29671144485473633
    },
    {
      "step": 430,
      "loss": 37.18481492996216,
      "learning_rate": 5.237932368834952e-05,
      "tokens_per_second": 26114.859413429647,
      "time": 0.3136911392211914
    },
    {
      "step": 440,
      "loss": 35.595423221588135,
      "learning_rate": 5.175558785279372e-05,
      "tokens_per_second": 26763.964623938507,
      "time": 0.30608320236206055
    },
    {
      "step": 450,
      "loss": 35.67814826965332,
      "learning_rate": 5.122358709262116e-05,
      "tokens_per_second": 28111.046324673604,
      "time": 0.2914156913757324
    },
    {
      "step": 460,
      "loss": 34.837010860443115,
      "learning_rate": 5.078542097178423e-05,
      "tokens_per_second": 25943.058003109265,
      "time": 0.3157684803009033
    },
    {
      "step": 470,
      "loss": 35.264487743377686,
      "learning_rate": 5.0442818731782785e-05,
      "tokens_per_second": 27015.68617534855,
      "time": 0.30323123931884766
    },
    {
      "step": 480,
      "loss": 35.01834297180176,
      "learning_rate": 5.0197132467138056e-05,
      "tokens_per_second": 25083.524808130744,
      "time": 0.32658886909484863
    },
    {
      "step": 490,
      "loss": 34.56869649887085,
      "learning_rate": 5.004933178929321e-05,
      "tokens_per_second": 27285.896886159924,
      "time": 0.3002283573150635
    },
    {
      "step": 500,
      "loss": 35.263264656066895,
      "learning_rate": 5e-05,
      "tokens_per_second": 27367.897409428773,
      "time": 0.2993288040161133
    }
  ],
  "validation_history": [
    {
      "step": 100,
      "train_loss": 7.642951574325561,
      "val_loss": 7.636784625053406,
      "eval_time": 12.916011571884155
    },
    {
      "step": 200,
      "train_loss": 5.674640524864197,
      "val_loss": 5.676810218811035,
      "eval_time": 12.888323545455933
    },
    {
      "step": 300,
      "train_loss": 4.890259510993958,
      "val_loss": 4.891550639152527,
      "eval_time": 12.602067232131958
    },
    {
      "step": 400,
      "train_loss": 4.558094191551208,
      "val_loss": 4.549616347312927,
      "eval_time": 12.602349758148193
    },
    {
      "step": 500,
      "train_loss": 4.363340597629547,
      "val_loss": 4.353469427585602,
      "eval_time": 13.535557985305786
    }
  ],
  "current_step": 500,
  "current_epoch": 0,
  "best_val_loss": 4.353469427585602,
  "model_info": {
    "total_parameters": 33997056,
    "trainable_parameters": 33997056,
    "model_size_mb": 129.6884765625,
    "layers": 6,
    "embedding_dim": 256,
    "hidden_dim": 1024,
    "heads": 8,
    "vocab_size": 50257
  },
  "training_info": {
    "batch_size": 16,
    "block_size": 64,
    "gradient_accumulation_steps": 8,
    "effective_batch_size": 128,
    "max_iters": 500,
    "learning_rate": 0.0001,
    "min_lr": 5e-05,
    "weight_decay": 0.1,
    "warmup_steps": 1000,
    "device": "cuda",
    "mixed_precision": false
  }
}