{
  "training_history": [
    {
      "step": 10,
      "loss": 84.06237697601318,
      "learning_rate": 9.995066821070681e-05,
      "tokens_per_second": 29169.468916366353,
      "time": 0.280841588973999
    },
    {
      "step": 20,
      "loss": 80.91930198669434,
      "learning_rate": 9.980286753286197e-05,
      "tokens_per_second": 28764.737953418517,
      "time": 0.2847931385040283
    },
    {
      "step": 30,
      "loss": 78.43934631347656,
      "learning_rate": 9.955718126821727e-05,
      "tokens_per_second": 28728.56596709233,
      "time": 0.28515172004699707
    },
    {
      "step": 40,
      "loss": 75.25838470458984,
      "learning_rate": 9.921457902821581e-05,
      "tokens_per_second": 28732.890268122723,
      "time": 0.2851088047027588
    },
    {
      "step": 50,
      "loss": 73.09281730651855,
      "learning_rate": 9.877641290737888e-05,
      "tokens_per_second": 27684.171130732968,
      "time": 0.29590916633605957
    },
    {
      "step": 60,
      "loss": 70.67849731445312,
      "learning_rate": 9.824441214720633e-05,
      "tokens_per_second": 27836.81987674255,
      "time": 0.29428648948669434
    },
    {
      "step": 70,
      "loss": 68.22036075592041,
      "learning_rate": 9.762067631165051e-05,
      "tokens_per_second": 29730.5954626751,
      "time": 0.2755410671234131
    },
    {
      "step": 80,
      "loss": 66.02731990814209,
      "learning_rate": 9.69076670010966e-05,
      "tokens_per_second": 28283.577428940676,
      "time": 0.28963804244995117
    },
    {
      "step": 90,
      "loss": 63.68404150009155,
      "learning_rate": 9.610819813755039e-05,
      "tokens_per_second": 28768.254180680415,
      "time": 0.2847583293914795
    },
    {
      "step": 100,
      "loss": 62.08316946029663,
      "learning_rate": 9.52254248593737e-05,
      "tokens_per_second": 28763.654358028183,
      "time": 0.2848038673400879
    },
    {
      "step": 110,
      "loss": 59.6369571685791,
      "learning_rate": 9.426283106939473e-05,
      "tokens_per_second": 27256.200212434982,
      "time": 0.3005554676055908
    },
    {
      "step": 120,
      "loss": 58.09744358062744,
      "learning_rate": 9.322421568553528e-05,
      "tokens_per_second": 28666.822712372632,
      "time": 0.2857658863067627
    },
    {
      "step": 130,
      "loss": 56.42597150802612,
      "learning_rate": 9.211367764821722e-05,
      "tokens_per_second": 28167.275515106005,
      "time": 0.2908339500427246
    },
    {
      "step": 140,
      "loss": 54.05128002166748,
      "learning_rate": 9.093559974371722e-05,
      "tokens_per_second": 28380.575485802172,
      "time": 0.2886481285095215
    },
    {
      "step": 150,
      "loss": 52.59839868545532,
      "learning_rate": 8.969463130731182e-05,
      "tokens_per_second": 28738.63399113746,
      "time": 0.2850518226623535
    },
    {
      "step": 160,
      "loss": 51.340819358825684,
      "learning_rate": 8.83956698744749e-05,
      "tokens_per_second": 28715.528874536587,
      "time": 0.2852811813354492
    },
    {
      "step": 170,
      "loss": 49.723859786987305,
      "learning_rate": 8.704384185254286e-05,
      "tokens_per_second": 28803.801835711452,
      "time": 0.2844069004058838
    },
    {
      "step": 180,
      "loss": 48.04131889343262,
      "learning_rate": 8.56444822891268e-05,
      "tokens_per_second": 28131.11554968258,
      "time": 0.29120779037475586
    },
    {
      "step": 190,
      "loss": 46.62166118621826,
      "learning_rate": 8.420311381711693e-05,
      "tokens_per_second": 27727.3326667748,
      "time": 0.29544854164123535
    },
    {
      "step": 200,
      "loss": 45.665353298187256,
      "learning_rate": 8.272542485937368e-05,
      "tokens_per_second": 28635.50159846654,
      "time": 0.28607845306396484
    },
    {
      "step": 210,
      "loss": 45.08632135391235,
      "learning_rate": 8.121724717912137e-05,
      "tokens_per_second": 28771.747175138877,
      "time": 0.28472375869750977
    },
    {
      "step": 220,
      "loss": 44.207040309906006,
      "learning_rate": 7.968453286464312e-05,
      "tokens_per_second": 28704.925461863764,
      "time": 0.2853865623474121
    },
    {
      "step": 230,
      "loss": 43.53260326385498,
      "learning_rate": 7.813333083910761e-05,
      "tokens_per_second": 27213.78058049115,
      "time": 0.3010239601135254
    },
    {
      "step": 240,
      "loss": 42.49179553985596,
      "learning_rate": 7.656976298823283e-05,
      "tokens_per_second": 27114.029224348204,
      "time": 0.30213141441345215
    },
    {
      "step": 250,
      "loss": 41.70610332489014,
      "learning_rate": 7.499999999999998e-05,
      "tokens_per_second": 27235.675493491846,
      "time": 0.3007819652557373
    },
    {
      "step": 260,
      "loss": 41.54810190200806,
      "learning_rate": 7.343023701176717e-05,
      "tokens_per_second": 27551.975777170497,
      "time": 0.2973289489746094
    },
    {
      "step": 270,
      "loss": 40.84697151184082,
      "learning_rate": 7.18666691608924e-05,
      "tokens_per_second": 27472.03273642239,
      "time": 0.29819416999816895
    },
    {
      "step": 280,
      "loss": 40.441081523895264,
      "learning_rate": 7.03154671353569e-05,
      "tokens_per_second": 28632.11318270527,
      "time": 0.28611230850219727
    },
    {
      "step": 290,
      "loss": 39.31079721450806,
      "learning_rate": 6.878275282087864e-05,
      "tokens_per_second": 27052.568964892806,
      "time": 0.30281782150268555
    },
    {
      "step": 300,
      "loss": 39.41321516036987,
      "learning_rate": 6.727457514062633e-05,
      "tokens_per_second": 29264.14788216577,
      "time": 0.27993297576904297
    },
    {
      "step": 310,
      "loss": 38.93754434585571,
      "learning_rate": 6.579688618288308e-05,
      "tokens_per_second": 27400.896969928963,
      "time": 0.2989683151245117
    },
    {
      "step": 320,
      "loss": 39.02117681503296,
      "learning_rate": 6.43555177108732e-05,
      "tokens_per_second": 28258.850382393844,
      "time": 0.28989148139953613
    },
    {
      "step": 330,
      "loss": 38.18163299560547,
      "learning_rate": 6.295615814745714e-05,
      "tokens_per_second": 28641.660068587127,
      "time": 0.28601694107055664
    },
    {
      "step": 340,
      "loss": 38.025935649871826,
      "learning_rate": 6.160433012552509e-05,
      "tokens_per_second": 28377.786175552137,
      "time": 0.28867650032043457
    },
    {
      "step": 350,
      "loss": 37.795565605163574,
      "learning_rate": 6.030536869268818e-05,
      "tokens_per_second": 27992.91728828362,
      "time": 0.2926454544067383
    },
    {
      "step": 360,
      "loss": 37.00329256057739,
      "learning_rate": 5.9064400256282764e-05,
      "tokens_per_second": 28366.072373662282,
      "time": 0.28879570960998535
    },
    {
      "step": 370,
      "loss": 36.988107204437256,
      "learning_rate": 5.788632235178279e-05,
      "tokens_per_second": 28727.941453414143,
      "time": 0.2851579189300537
    },
    {
      "step": 380,
      "loss": 36.846131801605225,
      "learning_rate": 5.677578431446471e-05,
      "tokens_per_second": 29136.12624620214,
      "time": 0.28116297721862793
    },
    {
      "step": 390,
      "loss": 37.336594581604004,
      "learning_rate": 5.5737168930605275e-05,
      "tokens_per_second": 29397.49928387968,
      "time": 0.27866315841674805
    },
    {
      "step": 400,
      "loss": 36.590566635131836,
      "learning_rate": 5.477457514062632e-05,
      "tokens_per_second": 27935.246295462195,
      "time": 0.29324960708618164
    },
    {
      "step": 410,
      "loss": 36.500492572784424,
      "learning_rate": 5.3891801862449625e-05,
      "tokens_per_second": 27219.90329414039,
      "time": 0.30095624923706055
    },
    {
      "step": 420,
      "loss": 36.35905599594116,
      "learning_rate": 5.3092332998903414e-05,
      "tokens_per_second": 28734.860659117156,
      "time": 0.28508925437927246
    },
    {
      "step": 430,
      "loss": 35.875905990600586,
      "learning_rate": 5.237932368834952e-05,
      "tokens_per_second": 28645.910480014405,
      "time": 0.28597450256347656
    },
    {
      "step": 440,
      "loss": 35.80160331726074,
      "learning_rate": 5.175558785279372e-05,
      "tokens_per_second": 27174.63025533749,
      "time": 0.30145764350891113
    },
    {
      "step": 450,
      "loss": 35.68302917480469,
      "learning_rate": 5.122358709262116e-05,
      "tokens_per_second": 28390.189914960985,
      "time": 0.28855037689208984
    },
    {
      "step": 460,
      "loss": 35.26832151412964,
      "learning_rate": 5.078542097178423e-05,
      "tokens_per_second": 28505.10363708313,
      "time": 0.2873871326446533
    },
    {
      "step": 470,
      "loss": 34.67595100402832,
      "learning_rate": 5.0442818731782785e-05,
      "tokens_per_second": 28068.70052036957,
      "time": 0.2918553352355957
    },
    {
      "step": 480,
      "loss": 35.09546947479248,
      "learning_rate": 5.0197132467138056e-05,
      "tokens_per_second": 28289.771776538742,
      "time": 0.28957462310791016
    },
    {
      "step": 490,
      "loss": 35.188026905059814,
      "learning_rate": 5.004933178929321e-05,
      "tokens_per_second": 25835.28330152772,
      "time": 0.31708574295043945
    },
    {
      "step": 500,
      "loss": 35.140310764312744,
      "learning_rate": 5e-05,
      "tokens_per_second": 25808.71686885902,
      "time": 0.3174121379852295
    }
  ],
  "validation_history": [
    {
      "step": 100,
      "train_loss": 7.693034181594848,
      "val_loss": 7.697778894424438,
      "eval_time": 11.605083227157593
    },
    {
      "step": 200,
      "train_loss": 5.719394743919373,
      "val_loss": 5.721293365478515,
      "eval_time": 11.62520432472229
    },
    {
      "step": 300,
      "train_loss": 4.911720815658569,
      "val_loss": 4.906622536659241,
      "eval_time": 11.722466230392456
    },
    {
      "step": 400,
      "train_loss": 4.5714351072311405,
      "val_loss": 4.566809768676758,
      "eval_time": 11.668535947799683
    },
    {
      "step": 500,
      "train_loss": 4.3692664670944215,
      "val_loss": 4.373450204372406,
      "eval_time": 12.167604446411133
    }
  ],
  "current_step": 500,
  "current_epoch": 0,
  "best_val_loss": 4.373450204372406,
  "model_info": {
    "total_parameters": 33997056,
    "trainable_parameters": 33997056,
    "model_size_mb": 129.6884765625,
    "layers": 6,
    "embedding_dim": 256,
    "hidden_dim": 1024,
    "heads": 8,
    "vocab_size": 50257
  },
  "training_info": {
    "batch_size": 16,
    "block_size": 64,
    "gradient_accumulation_steps": 8,
    "effective_batch_size": 128,
    "max_iters": 500,
    "learning_rate": 0.0001,
    "min_lr": 5e-05,
    "weight_decay": 0.1,
    "warmup_steps": 1000,
    "device": "cuda",
    "mixed_precision": false
  }
}